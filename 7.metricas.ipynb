{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59438898-01a1-4232-9ccc-fb7d688d1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hdbscan\n",
    "from hdbscan.validity import validity_index\n",
    "from sklearn.manifold import trustworthiness\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d943f58-0e72-4d3c-be43-98658b937e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('./data/Gold/Gold_embedding_imagen_marca.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9392178d-360c-4f1f-9842-818bb1bcfe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = df[['UMAP_1', 'UMAP_2', 'UMAP_3']].values\n",
    "labels = df['clusters_hdbscan'].values\n",
    "\n",
    "embeddings_originales = np.load('./data/Silver/embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618433ff-a7bf-4703-b6d0-1f72c8fb762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### evalua calidad embedding UMAP\n",
    "\n",
    "\n",
    "### se necesita hacerun submuuestreo porque crea una matriz tan grande que necesita 129 gigas. \n",
    "\n",
    "# aprox 25% de las muestras\n",
    "n_sample = 32870  \n",
    "N = embeddings.shape[0]  \n",
    "np.random.seed(69) \n",
    "sample_idx = np.random.choice(N, size=n_sample, replace=False)\n",
    "\n",
    "\n",
    "# Aplicar los índices a ambos arrays\n",
    "embedded_muestro = embeddings[sample_idx]\n",
    "original_muestreo = embeddings_originales[sample_idx]\n",
    "\n",
    "\n",
    "trust_score = trustworthiness(original_muestreo ,\n",
    "                              embedded_muestro,\n",
    "                              n_neighbors=100 ### mismo que en UMAP\n",
    "                             )\n",
    "print(f\"Trustworthiness: {trust_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94fbcbd-cda8-4962-88b1-9f222a7bed95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c549f569-c079-4e51-806e-933bb4ab1c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "##quiere labels numericos \n",
    "categorias = set(labels)\n",
    "\n",
    "# Crear mapping\n",
    "categorias_lista = sorted(categorias)\n",
    "categoria2id = {}\n",
    "i = 0\n",
    "for cat in categorias_lista:\n",
    "    if cat == \"Desconectado\":\n",
    "        categoria2id[cat] = -1\n",
    "    else:\n",
    "        categoria2id[cat] = i\n",
    "        i += 1\n",
    "labels_numericos = [categoria2id[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f38ffc-df68-4034-9732-c96fc26b40d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### evaluación clustering HDBSCAN \n",
    "# se emplea Density-Based Clustering Validation comoo métrica de evaluación, para clusters de densidad. \n",
    "#https://github.com/christopherjenness/DBCV/blob/master/DBCV/DBCV.py  \n",
    "# -->> esta implementación es miuy lenta y para este dataset es tan grande que se opta por al de hdbscan que se basa en cython, aunque es menos precisa.\n",
    "# \n",
    "#se hace sobre el embedding final\n",
    "\n",
    "\n",
    "\n",
    "score = validity_index(\n",
    "                       np.array(embeddings, dtype=np.float64), \n",
    "                       np.array(labels_numericos)\n",
    "                       )\n",
    "print(\"DBCV:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba8da19-b7f6-40a8-acff-bb8bc8ae0fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_ou t= df[df['clusters_hdbscan']!='Desconectado']\n",
    "df_sin_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d71f4c4-e5bf-44d5-bec9-f8dd5ea985f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_wo = df_sin_out[['UMAP_1', 'UMAP_2', 'UMAP_3']].values\n",
    "labels_wo = df_sin_out['clusters_hdbscan'].values\n",
    "\n",
    "##quiere labels numericos \n",
    "categorias = set(labels)\n",
    "\n",
    "# Crear mapping\n",
    "categorias_lista = sorted(categorias)\n",
    "categoria2id = {}\n",
    "i = 0\n",
    "for cat in categorias_lista:\n",
    "    if cat == \"Desconectado\":\n",
    "        categoria2id[cat] = -1\n",
    "    else:\n",
    "        categoria2id[cat] = i\n",
    "        i += 1\n",
    "labels_numericos_wo = [categoria2id[label] for label in labels_wo ]\n",
    "\n",
    "score = validity_index(\n",
    "                       np.array(embeddings_wo, dtype=np.float64), \n",
    "                       np.array(labels_numericos_wo )\n",
    "                       )\n",
    "print(\"DBCV sin desconectados:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41678272-3308-43a0-9596-b02cc8c7abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############  ACONTINUACIÓN SE VA A ANALIZAR EL ACCURACY DE LA CLASIFICACIÓN SOBRE LA TAXONOMIA DE MERCADONA\n",
    "\n",
    "df = pd.read_parquet('./data/Silver/Cleaned_data_features_productos_categorias.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07745fe1-eff3-4ab7-8064-f632e60088d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset\n",
    "subset = df[df['sentimiento_producto']=='SI'].sample(n=100, random_state=69)\n",
    "subset.to_excel('manual_label_categorias.xlsx', index=False)\n",
    "\n",
    "#se hace un manual label \n",
    "#valores binarios:\n",
    "#    1 bien categorizado \n",
    "#    0 No está bien clasificado.\n",
    "## si habla de productos de navidad se deja a 1 porque no se puede categorizar con el catalogo actual y no se considera que falla\n",
    "## Notas: \n",
    "## hummus falla bastante\n",
    "## cuando se habla algo  de hacendado (despectivo) falla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94977c5e-a8df-4ed3-bd15-bb2520f3c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_manual = pd.read_excel('./data/Silver/manual_label_categorias_manual_label.xlsx')\n",
    "df_manual['automatic_label'] = [1] * len(df_manual)\n",
    "df_manual = df_manual[['manual_label','automatic_label']]\n",
    "df_manual = df_manual.fillna(1)\n",
    "#df_manual = df_manual.dropna(subset=['manual_label'])\n",
    "df_manual['manual_label'] = df_manual['manual_label'].astype(int)\n",
    "df_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1868c4-48f9-46fd-9c8a-b95c51e551e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df_manual['manual_label']\n",
    "y_pred = df_manual['automatic_label']\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
