{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2c8cc-018e-4e3b-a587-0686a21d31ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_ind, mannwhitneyu \n",
    "from wordcloud import WordCloud\n",
    "from PIL import Image\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import spacy\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074483f-4d25-4b7f-9a87-52fad2a8c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "route = \"./data/Bronze\" \n",
    "\n",
    "elements = os.listdir(route)\n",
    "\n",
    "\n",
    "files_mercadona = [element for element in elements if element.startswith(\"mercadona\") and os.path.isfile(os.path.join(route, element))]\n",
    "files_hacendado = [element for element in elements if element.startswith(\"hacendado\") and os.path.isfile(os.path.join(route, element))]\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of elementes:\", len(elements))\n",
    "print(\"Number of Mercadona files:\", len(files_mercadona))\n",
    "print(\"Number of hacendado files:\", len(files_hacendado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b593f5-69ca-4398-a81e-cc99df4cea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#empezamos por los mensajes que contienen la palabra mercadona\n",
    "\n",
    "mercadona_merged = pd.DataFrame()\n",
    "\n",
    "mercadona_day = []\n",
    "counts_tweets_mercadona = [] \n",
    "\n",
    "for i in files_mercadona:\n",
    "    \n",
    "    #dia\n",
    "    b = i.strip(\"mercadona dia \")\n",
    "    day = b.strip(\".xlsx\")\n",
    "    mercadona_day.append(day)\n",
    "\n",
    "    df = pd.read_excel('./data/Bronze/'+i)\n",
    "\n",
    "    #guardar len de archivo\n",
    "    lenght_file = len(df)\n",
    "    counts_tweets_mercadona.append(lenght_file)\n",
    "\n",
    "    #unir df\n",
    "    mercadona_merged = pd.concat([mercadona_merged, df], ignore_index=True)\n",
    "\n",
    "\n",
    "mercadona_merged\n",
    "\n",
    "\n",
    "mercadona_longitud = len(mercadona_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7707fab5-f4a2-4930-8809-8e0f4ee80331",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_counts = pd.DataFrame({\n",
    "    'tweets count': counts_tweets_mercadona,\n",
    "    'Day': pd.to_datetime(mercadona_day),\n",
    "    'Type': 'mercadona'\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(15,6)) \n",
    "plt.bar(mercadona_counts['Day'],mercadona_counts['tweets count'])\n",
    "plt.title(\"Nº tweets Mercadona por día\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Numero tweets mercadona: \", len(mercadona_merged))\n",
    "merca_days_Zero_TW = len(mercadona_counts[mercadona_counts['tweets count'] == 0])\n",
    "print('Numero de archvios con count  0: ', merca_days_Zero_TW)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb52cbb-6f7d-4fba-8f4e-ca2f4c77e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicates = mercadona_counts.duplicated().sum()\n",
    "print(f\"Numero duplicados: {num_duplicates}\")\n",
    "\n",
    "\n",
    "duplicados_unicos = mercadona_merged['tweets'][mercadona_merged['tweets'].duplicated()].unique()\n",
    "print(\"Numero Tweets duplicados: \", len(duplicados_unicos))\n",
    "\n",
    "tweets_duplicados = mercadona_merged['tweets'].str.lower().value_counts() # duplicates in lower case\n",
    "tweets_duplicados = tweets_duplicados[tweets_duplicados > 1]\n",
    "df_tweets_duplicados = pd.DataFrame(tweets_duplicados)\n",
    "print(\"number of duplicates in lowercase: \", len(df_tweets_duplicados))\n",
    "df_tweets_duplicados.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b8084-c3e2-464d-a557-2ae9905e48f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se observa que hay varios mensajes con alta frecuencia.\n",
    "# Se verificará si provienen de los mismos usuarios o de usuarios diferentes.\n",
    "# Si son de los mismos usuarios, se eliminan.\n",
    "# Además, notamos que algunos usuarios tienen \"mercadona\" en sus nombres de usuario, \n",
    "# por lo que mantendremos solo los mensajes que mencionen explícitamente \"mercadona\" y eliminaremos el resto.\n",
    "\n",
    "mercadona_merged.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d187c49-b494-4c66-b84d-c477414c06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Bot MasterHdeRepollo\n",
    "print(mercadona_merged[mercadona_merged['tweets'].str.lower()==\"me voy a la inaguracion del mercadona de mi pueblo!!\"]['User'].value_counts())\n",
    "print(mercadona_merged[mercadona_merged['User']==\"MasterHdeRepollo\"]['tweets'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787f94a-9e5f-48d0-bf27-44a788885b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_merged[mercadona_merged['tweets'].str.lower()==\"polla sabor helado de nubes del mercadona\"]['User'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2ff403-3ad9-499d-a62e-60145c6a919f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_merged[mercadona_merged['tweets'].str.lower()==\"coño sabor helado de nubes del mercadona\"]['User'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd3d948-8211-48c5-9118-ccd32367ee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bot genitalesabores_bot\n",
    "print(mercadona_merged[mercadona_merged['User']==\"genitalesabores_bot\"]['tweets'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c20f3-fed7-4bae-90f9-a57f670e9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_merged[mercadona_merged['tweets'].str.lower()==\"mercadona\"]['User'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95556d04-4380-4e2c-99c4-35855b514ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_merged[mercadona_merged['tweets'].str.lower()==\"quiero chupachups azules y zumitos del mercadona\"]['User'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e41b5d6-a1d3-48b7-bcd4-a152387b42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mercadona_merged[mercadona_merged['User']==\"ansufatisima (roja no, rojisima)\"]['tweets'].value_counts())\n",
    "#no parece un bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7083df-c042-4af6-aae9-19fa04b8081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_merged[mercadona_merged['tweets'].str.lower()==\"el día que suban de precio el vodka knebep de 4 euros de mercadona se lía la de dios.\"]['User'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1adb5-dbc2-4a84-974d-d0ba5880192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_merged[mercadona_merged['tweets'].str.lower()==\"mucho polito ralph lauren y mucha camisa tommy hilfiger pero para el botellón compráis ron de 5 euros del mercadona.\"]['User'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c90169-17f5-4b98-b8a4-02155cb9c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Este usuario tiene 17486 mensajes pero solamente 7 hablan de mercadona. se eliminam los tweets que no contengan mercadona\n",
    "\n",
    "print(mercadona_merged[mercadona_merged['User']==\"pasillo de mercadona\"]['tweets'].value_counts())\n",
    "\n",
    "\n",
    "mercadona_merged[\n",
    "    (mercadona_merged['User'] == \"pasillo de mercadona\") &\n",
    "    (mercadona_merged['tweets'].str.lower().str.contains(\"mercadona\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8f45a-5c1e-4b7a-8519-fa634dc0d0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tweets Number: \", len(mercadona_merged))\n",
    "\n",
    "print(\"Tweets Number that contain mercadona in tweets colum: \",  len(mercadona_merged[mercadona_merged['tweets'].str.lower().str.contains(\"mercadona\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6d68d-af98-43c5-8bbc-bae8cfc1cb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_merged_clean = mercadona_merged[mercadona_merged['User'] != \"genitalesabores_bot\"]\n",
    "mercadona_merged_clean = mercadona_merged_clean[mercadona_merged_clean ['User'] != \"MasterHdeRepollo\"]\n",
    "mercadona_merged_clean = mercadona_merged_clean[mercadona_merged_clean['tweets'].str.lower().str.contains(\"mercadona\")]\n",
    "mercadona_drop_tw = (len(mercadona_merged) - len(mercadona_merged_clean))\n",
    "print(\"Tweets cleaned = \", mercadona_drop_tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4134b-d8e9-4918-8e87-d157c0691fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## por algun motivo no se ha guardado el nombre de algunos usuarios, seguramente por contener caracteres extraños.\n",
    "print(mercadona_merged_clean.isna().sum())\n",
    "mercadona_nan = len(mercadona_merged_clean[mercadona_merged_clean['User'].isna()])\n",
    "mercadona_merged_clean[mercadona_merged_clean['User'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b27dd6-13e1-4c16-962c-ec57ebb51ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_merged_clean[mercadona_merged_clean['User']==\"USER_EMPTY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15220df6-4885-43d1-8248-f017b45681d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imputar \"USER_EMPTY\" en usuarios NaN. Aunque en el analisis no se utilizarán los nombres por protección de datos.\n",
    "mercadona_merged_clean['User'] = mercadona_merged_clean['User'].fillna(\"USER_EMPTY\")\n",
    "mercadona_merged_clean[mercadona_merged_clean['User']==\"USER_EMPTY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacee778-ec75-4bba-b523-ac5611467615",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mercadona_merged_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a3ae07-5824-4906-9061-b556070fd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_merged_clean = mercadona_merged_clean[~mercadona_merged_clean['tweets'].str.replace(r'\\s+', ' ', regex=True)\n",
    "                      .str.strip()\n",
    "                      .str.lower()\n",
    "                      .duplicated()]\n",
    "mercadona_merged_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035f5bee-1aa4-48fc-8f1f-ec5f37cefca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobamos\n",
    "duplicados_unicos = mercadona_merged_clean['tweets'][mercadona_merged_clean['tweets'].duplicated()].unique()\n",
    "print(\"Number of duplicates Tweets: \", len(duplicados_unicos))\n",
    "\n",
    "tweets_duplicados = mercadona_merged_clean['tweets'].str.lower().value_counts() # duplicates in lower case\n",
    "tweets_duplicados = tweets_duplicados[tweets_duplicados > 1]\n",
    "df_tweets_duplicados = pd.DataFrame(tweets_duplicados)\n",
    "print(\"number of duplicates in lowercase: \", len(df_tweets_duplicados))\n",
    "df_tweets_duplicados.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ddc7d9-3e46-4800-8ebc-75692e6af380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#es el turno de hacendado\n",
    "\n",
    "hacendado_merged = pd.DataFrame()\n",
    "\n",
    "hacendado_day = []\n",
    "counts_tweets_hacendado = [] \n",
    "\n",
    "for i in files_hacendado:\n",
    "    \n",
    "    #save file day\n",
    "    b = i.strip(\"hacendado dia \")\n",
    "    day = b.strip(\".xlsx\")\n",
    "    hacendado_day.append(day)\n",
    "\n",
    "    df = pd.read_excel('./data/Bronze/'+i)\n",
    "\n",
    "    #save file lenght in a list\n",
    "    lenght_file = len(df)\n",
    "    counts_tweets_hacendado.append(lenght_file)\n",
    "\n",
    "    #merge all files in a single df\n",
    "    hacendado_merged = pd.concat([hacendado_merged, df], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "hacendado_longitud = len(hacendado_merged)\n",
    "\n",
    "hacendado_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa165b1-41e2-4bec-83f1-06ccef2df34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hacendado_counts = pd.DataFrame({\n",
    "    'tweets count': counts_tweets_hacendado,\n",
    "    'Day': pd.to_datetime(hacendado_day),\n",
    "    'Type': 'hacendado'\n",
    "})\n",
    "plt.figure(figsize=(15,6)) \n",
    "plt.bar(hacendado_counts['Day'],hacendado_counts['tweets count'])\n",
    "plt.title(\"Nº tweets hacendado por día\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Number of hacendado tweets: \", len(hacendado_merged))\n",
    "print('Number of days with a tweet count of 0: ', len(hacendado_counts[hacendado_counts['tweets count'] == 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f8440-bf2a-4c62-abdf-218911015fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_duplicates = hacendado_counts.duplicated().sum()\n",
    "print(f\"Number of duplicates: {num_duplicates}\")\n",
    "\n",
    "\n",
    "duplicados_unicos = hacendado_merged['tweets'][hacendado_merged['tweets'].duplicated()].unique()\n",
    "print(\"Number of duplicates Tweets: \", len(duplicados_unicos))\n",
    "\n",
    "tweets_duplicados = hacendado_merged['tweets'].str.lower().value_counts() # duplicates in lower case\n",
    "tweets_duplicados = tweets_duplicados[tweets_duplicados > 1]\n",
    "df_tweets_duplicados = pd.DataFrame(tweets_duplicados)\n",
    "print(\"number of duplicates in lowercase: \", len(df_tweets_duplicados))\n",
    "df_tweets_duplicados.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b00143-64c0-46b6-a343-8c2795511ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hacendado_merged['User'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4492300-e206-4e4b-bb02-836b8034f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(hacendado_merged[hacendado_merged['User']==\"DARIAK\"]['tweets'].value_counts())\n",
    "\n",
    "\n",
    "# hacendado_merged[\n",
    "#     (hacendado_merged['User'] == \"DARIAK\") &\n",
    "#     (hacendado_merged['tweets'].str.lower().str.contains(\"hacendado\"))\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ec600-0417-457b-841e-00ec733aa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mercadona_hacendado[mercadona_hacendado['tweets']==\"hacendado\"]  poner para borrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96706a55-7948-4710-a31f-ef789f10c4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "hacendado_merged_clean =  hacendado_merged[hacendado_merged['tweets'].str.lower().str.contains(\"hacendado\")]\n",
    "hacendado_merged_clean = hacendado_merged_clean[~hacendado_merged_clean['tweets'].str.replace(r'\\s+', ' ', regex=True)\n",
    "                      .str.strip()\n",
    "                      .str.lower()\n",
    "                      .duplicated()]\n",
    "\n",
    "\n",
    "hacendado_drop_tw = (len(hacendado_merged) - len(hacendado_merged_clean))\n",
    "print(\"Tweets cleaned = \", hacendado_drop_tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96abad20-d2d2-47c7-9763-ced1fa772f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "hacendado_merged_clean['User'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e35d6dd-0ea4-4f01-bf90-81349c15a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se detectan estos bots\n",
    "# Infladona              \n",
    "# Precio carrito de la compra \n",
    "print(len(hacendado_merged_clean))\n",
    "hacendado_merged_clean = hacendado_merged_clean[hacendado_merged_clean ['User'] != \"Infladona\"]\n",
    "hacendado_merged_clean = hacendado_merged_clean[hacendado_merged_clean ['User'] != \"Precio carrito de la compra \"]\n",
    "print(len(hacendado_merged_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab66155-8564-4a30-a5ca-60f849bd1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in hacendado_merged_clean['tweets'][hacendado_merged_clean ['User'] == \".\"]:\n",
    "#     print(\"====\")\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92092ec3-0e18-4c86-9d8f-44460b6c1ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hacendado_merged_clean.isna().sum())\n",
    "hacendado_nan = len(hacendado_merged_clean[hacendado_merged_clean['User'].isna()])\n",
    "hacendado_merged_clean[hacendado_merged_clean['User'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca2c89-705b-4fc5-8312-1b8961d83a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "hacendado_merged_clean['User'] = hacendado_merged_clean['User'].fillna(\"USER_EMPTY\")\n",
    "hacendado_merged_clean[hacendado_merged_clean['User']==\"USER_EMPTY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d7e6ae-6053-46ab-b004-8772faf4ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "hacendado_merged_clean[hacendado_merged_clean['User'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fe8b8d-3f40-4735-83c9-1a4b43a208fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "densidad tweets día\n",
    "sns.kdeplot(data=mercadona_counts, x='tweets count', hue='Type', fill=True, common_norm=True) \n",
    "plt.title(\"Histograma nº tweets/día\")\n",
    "plt.show()\n",
    "\n",
    "sns.kdeplot(data=hacendado_counts, x='tweets count', hue='Type', fill=True, common_norm=True) \n",
    "plt.title(\"Hacendado nº tweets/día\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc8e8b-e15a-489e-83de-672fd87a45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### \n",
    "\n",
    "print(f\"\"\"Resumen de la búsqueda:\n",
    "\n",
    "========== Mercadona =========\n",
    "\n",
    "Se recopiló {len(files_mercadona)} archivos, un archivo por día durante diez años — de los cuales solo {merca_days_Zero_TW} días no tuvieron tweets.\n",
    "\n",
    "En total, se obtuvieron {len(mercadona_merged)} tweets en este período de diez años.\n",
    "\n",
    "Se eliminó {mercadona_drop_tw} mensajes correspondientes a bots o tweets que no contenían la palabra clave \"mercadona\",\n",
    "lo que resultó en un conteo final de {len(mercadona_merged_clean)} tweets.\n",
    "\n",
    "Además, se imputó {mercadona_nan} valores de usuario faltantes (NaN) con \"USER_EMPTY\".\n",
    "\n",
    "\n",
    "========== hacendado =========\n",
    "\n",
    "Se recopiló {len(files_hacendado)} archivos, un archivo por día durante diez años — de los cuales solo {merca_days_Zero_TW} días no tuvieron tweets.\n",
    "\n",
    "En total, se obtuvieron {len(hacendado_merged)} tweets en este período de diez años.\n",
    "\n",
    "Se eliminó {hacendado_drop_tw} mensajes correspondientes a bots o tweets que no contenían la palabra clave \"hacendado\",\n",
    "lo que resultó en un conteo final de {len(hacendado_merged_clean)} tweets.\n",
    "\n",
    "Además, se imputó {hacendado_nan} valores de usuario faltantes (NaN) con \"USER_EMPTY\".\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65379da-f2c6-4bf7-8201-5132b39f264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unimos los dos dataframes\n",
    "mercadona_hacendado = pd.concat([mercadona_merged_clean, hacendado_merged_clean], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efabc80a-eecc-4feb-9dac-694489b7a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobar los duplciados en columnas fechaq tweet y usuario. los que tienen mercadona y hacedando\n",
    "duplicados = mercadona_hacendado.duplicated(subset=['User', 'tweets', 'fecha_captura'], keep=False)\n",
    "filas_duplicadas = mercadona_hacendado[duplicados]\n",
    "filas_duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a64bda1-2027-4927-8f55-d7b31065e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(mercadona_hacendado))\n",
    "mercadona_hacendado.drop_duplicates(subset=['User', 'tweets', 'fecha_captura'], inplace=True)\n",
    "print(len(mercadona_hacendado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767dad18-95b1-4346-9c6f-2f5fa84cf43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def len_tweets_plot(mercadona_hacendado, nombre: str):\n",
    "    # Calcular longitud de texto\n",
    "    mercadona_hacendado[\"char_len\"] = mercadona_hacendado[\"tweets\"].apply(lambda x: len(x))\n",
    "\n",
    "    mercadona = mercadona_hacendado[mercadona_hacendado['search'] == 'mercadona']['char_len']\n",
    "    hacendado = mercadona_hacendado[mercadona_hacendado['search'] == 'hacendado']['char_len']\n",
    "    #cálculo medias y desviación\n",
    "    media_mercadona = mercadona.mean()\n",
    "    media_hacendado = hacendado.mean()\n",
    "    std_mercadona = mercadona.std()\n",
    "    std_hacendado = hacendado.std()\n",
    "\n",
    "    # Crear gráfico de distribución\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.kdeplot(data=mercadona_hacendado, x=\"char_len\", hue=\"search\", fill=True, common_norm=True) #common_norm=True\n",
    "    # Añadir líneas de media\n",
    "    plt.axvline(media_mercadona, color='blue', linestyle='--', linewidth=1, label='Media mercadonas')\n",
    "    plt.axvline(media_hacendado, color=\"orange\", linestyle='--', linewidth=1, label='Media hacendado')\n",
    "    plt.text(media_mercadona + 2, plt.ylim()[1]*0.8, f\"Media mercadona: {int(media_mercadona)}, std:{int(std_mercadona)} \", color='blue', fontsize=10)\n",
    "    plt.text(media_hacendado + 2, plt.ylim()[1]*0.6, f\"Media hacendado: {int(media_hacendado)}, std:{int(std_hacendado)}\", color='orange', fontsize=10)\n",
    "\n",
    "    plt.xlabel('Número de caracteres', fontsize=16)\n",
    "    plt.ylabel('Densidad', fontsize=16)\n",
    "    plt.title(f'Distribución de longitud de texto en {nombre}', fontsize=18)\n",
    "    plt.show();\n",
    "\n",
    "    #test diferencia de medias.\n",
    "    t_stat, p_value = ttest_ind(mercadona, hacendado,  equal_var=False)\n",
    "    if p_value<0.05:\n",
    "      print(f\"La diferencia de medias ES estadísticamente significativa, p_value:{p_value:.4f}\")\n",
    "    else:\n",
    "       print(f\" La diferencia de medias NO es estadísticamente significativa, p_value:{p_value:.4f}\")\n",
    "    print(100*(\"=\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "len_tweets_plot(mercadona_hacendado, \"Hacendatos\")\n",
    "print(100*(\"=\"))\n",
    "print(100*(\"=\"))\n",
    "print(100*(\"=\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bade967-ad2c-4027-928c-06b6d5404e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se observa que hay algunos tweets con un numero de caracteres excesivos.  y con contenido que podría confundir a los modelos del lenguaje.\n",
    "# por tanto se procede a buscar un punto de corte adecuado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4164ce97-dfd7-4f2a-9cd0-cadb39f23dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in mercadona_hacendado['tweets'][mercadona_hacendado['char_len'] > 300]:\n",
    "#     print(\"===\")\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a1df4-720a-4f30-9d17-02e98b5b8fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_hacendado.sort_values(by='char_len', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e25aaf-0553-45e8-9857-20c3d50ae12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mercadona_hacendado['char_len'][mercadona_hacendado['char_len'] < 350], bins=10, edgecolor='black') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49611d2b-e7f4-4dff-8565-7d01cac0a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mercadona_hacendado['char_len'][(mercadona_hacendado['char_len'] > 280) & (mercadona_hacendado['char_len'] < 350)], bins=10, edgecolor='black') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864e1c4-121d-4f14-9cf5-1fb1739a7526",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_hacendado['char_len'][mercadona_hacendado['char_len'] > 280].count()\n",
    "## son valores atipicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd7939-be2d-4d89-a056-75eed54b59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### bsucamos outlier con z-score\n",
    "\n",
    "mercadona_hacendado['z_score'] = (mercadona_hacendado['char_len']- mercadona_hacendado['char_len'].mean()) / mercadona_hacendado['char_len'].std()\n",
    "outliers_mask = np.abs(mercadona_hacendado['z_score']) > 3\n",
    "\n",
    "outliers = mercadona_hacendado[outliers_mask]\n",
    "outliers.sort_values(by='char_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ea054-a402-41dc-9768-87d5b7e35d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mercadona_hacendado['z_score_por_grupo'] = mercadona_hacendado.groupby('search')['char_len'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "# Ahora puedes identificar los outliers\n",
    "outliers_mask = np.abs(mercadona_hacendado['z_score_por_grupo']) > 3\n",
    "\n",
    "# Filtra y muestra los outliers\n",
    "outliers = mercadona_hacendado[outliers_mask]\n",
    "outliers_sorted_grouped = outliers.sort_values(by='char_len', ascending=True).groupby('search')\n",
    "for name, group in outliers_sorted_grouped:\n",
    "    print(f\"\\nGrupo: {name}\")\n",
    "    print(group.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8903aa0-9382-4cff-93b7-bc47123fbcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rango inter quartilico. \n",
    "Q1 = mercadona_hacendado['char_len'].quantile(0.25)\n",
    "Q3 = mercadona_hacendado['char_len'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(f\"Q1: {Q1}\")\n",
    "print(f\"Q3: {Q3}\")\n",
    "print(f\"IQR: {IQR}\")\n",
    "\n",
    "## capturo mejor los outliers con z_score por grupo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48aa317-20f9-48d7-9002-d339b579ab31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08ef4a-e7ed-4e26-8175-cfad24874531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1599a0a7-135c-40b8-a64e-df2a39a1f473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8829332e-cd7d-4368-867f-a5002d4d2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# se determina un puto de corte mediante el z_score popr grupo, ya que no sabemos si existen diferencias entre ellos.  \n",
    "a = len(mercadona_hacendado)\n",
    "print(len(mercadona_hacendado))\n",
    "mercadona_hacendado = mercadona_hacendado[np.abs(mercadona_hacendado['z_score_por_grupo']) < 3]\n",
    "print(len(mercadona_hacendado))\n",
    "b= len(mercadona_hacendado)\n",
    "print(a-b) #capturo 3 outlier más que solo por grupo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304b9ac2-5fa6-49b7-a361-70df981e528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c74720-9e94-4655-aa80-7b697a3c0b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def len_tweets_plot(mercadona_hacendado, nombre: str):\n",
    "    # Calcular longitud de texto\n",
    "    mercadona_hacendado[\"char_len\"] = mercadona_hacendado[\"tweets\"].apply(lambda x: len(x))\n",
    "\n",
    "    mercadona = mercadona_hacendado[mercadona_hacendado['search'] == 'mercadona']['char_len']\n",
    "    hacendado = mercadona_hacendado[mercadona_hacendado['search'] == 'hacendado']['char_len']\n",
    "    #cálculo medias y desviación\n",
    "    media_mercadona = mercadona.mean()\n",
    "    media_hacendado = hacendado.mean()\n",
    "    std_mercadona = mercadona.std()\n",
    "    std_hacendado = hacendado.std()\n",
    "\n",
    "    # Crear gráfico de distribución\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    sns.kdeplot(data=mercadona_hacendado, x=\"char_len\", hue=\"search\", fill=True, common_norm=False) #common_norm=True\n",
    "    # Añadir líneas de media\n",
    "    plt.axvline(media_mercadona, color='blue', linestyle='--', linewidth=1, label='Media mercadonas')\n",
    "    plt.axvline(media_hacendado, color=\"orange\", linestyle='--', linewidth=1, label='Media hacendado')\n",
    "    plt.text(media_mercadona + 2, plt.ylim()[1]*0.8, f\"Media mercadona: {int(media_mercadona)}, std:{int(std_mercadona)} \", color='blue', fontsize=10)\n",
    "    plt.text(media_hacendado + 2, plt.ylim()[1]*0.6, f\"Media hacendado: {int(media_hacendado)}, std:{int(std_hacendado)}\", color='orange', fontsize=10)\n",
    "\n",
    "    plt.xlabel('Número de caracteres', fontsize=16)\n",
    "    plt.ylabel('Densidad', fontsize=16)\n",
    "    plt.title(f'Distribución de longitud de texto en {nombre}', fontsize=18)\n",
    "    plt.show();\n",
    "\n",
    "    #test diferencia de medias.\n",
    "    t_stat, p_value = ttest_ind(mercadona, hacendado,  equal_var=False)  # equal_var=False Welch’s t-test comparar medias sin asumir varianzas iguales. con muchos datos\n",
    "    #t_stat, p_value = mannwhitneyu(mercadona, hacendado) \n",
    "    if p_value<0.05:\n",
    "      print(f\"La diferencia de medias ES estadísticamente significativa, p_value:{p_value:.4f}\")\n",
    "    else:\n",
    "       print(f\" La diferencia de medias NO es estadísticamente significativa, p_value:{p_value:.4f}\")\n",
    "    print(100*(\"=\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "len_tweets_plot(mercadona_hacendado, \"Hacendatos\")\n",
    "print(100*(\"=\"))\n",
    "print(100*(\"=\"))\n",
    "print(100*(\"=\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42321d1e-0a7d-4e36-86dd-7b62dda22ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Tweets procesados: ')\n",
    "print(mercadona_longitud + hacendado_longitud)\n",
    "print('Numero de items limpiados: ')\n",
    "print(mercadona_longitud + hacendado_longitud - len(mercadona_hacendado))\n",
    "print('Numero de tweets a la siguiente fase: ')\n",
    "print(len(mercadona_hacendado))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad5c5b-ae8f-436a-892e-8f25978574e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweets procesados: \n",
    "# 408784\n",
    "# Numero de items limpiados: \n",
    "# 53270\n",
    "# Numero de tweets a la siguiente fase: \n",
    "# 355514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce9ba8a-907e-4cf4-8545-7dc35335f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_hacendado.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e20b9f-d902-444b-9dd0-a87ce418c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardado para procesado de LOPD\n",
    "mercadona_hacendado = mercadona_hacendado[['User', 'tweets', 'search', 'fecha_captura']]\n",
    "mercadona_hacendado.to_parquet('./data/Silver/Cleaned_data.parquet' ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8629588-3404-4b5e-a1fe-e4d6476b3e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mercadona_hacendado = pd.read_parquet( './data/Silver/Cleaned_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac3acf8-105f-4d82-b89b-8469860e81b7",
   "metadata": {},
   "outputs": [],
   "source": [
    " #modelo mediano español spicy\n",
    "nlp = spacy.load('es_core_news_md', disable=['parser', 'ner'])\n",
    "#stop_words en español\n",
    "es_stopwords = stopwords.words('spanish') # 'english'\n",
    "# iniciar Tokenizador\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "\n",
    "\n",
    "# Eliminar espacios\n",
    "def eliminar_espacios(text):\n",
    "    return  \" \".join(text.split())\n",
    "\n",
    "# To lower\n",
    "def texto_to_lower(text):\n",
    "  return text.lower()\n",
    "\n",
    "def normalizar_tokens(documento):\n",
    "    # Dividir el documento en palabras\n",
    "    palabras =  tweet_tokenizer.tokenize(documento) # tokenize(documento)\n",
    "\n",
    "    # Reemplazar URLs, menciones de Twitter y números por los tokens correspondientes\n",
    "    for i in range(len(palabras)):\n",
    "        if palabras[i].startswith(\"http://\") or palabras[i].startswith(\"https://\") or palabras[i].startswith(\"www.\"):\n",
    "            palabras[i] = \"URL\"\n",
    "        elif palabras[i].startswith(\"@\"): #tokenize(documento)\n",
    "            palabras[i] = \"MENTION\"\n",
    "        #elif palabras[i].isdigit():\n",
    "        elif palabras[i].isdigit(): #\n",
    "            palabras[i] = \"NUM\"\n",
    "    # Unir las palabras de nuevo en un documento modificado\n",
    "    palabras = set(palabras) # para que no aparezcan cosas como MENTION MENTION,  NUM NUM, URL URL\n",
    "    documento_modificado = ' '.join(palabras)\n",
    "\n",
    "\n",
    "    return documento_modificado\n",
    "\n",
    "\n",
    "def lematizar_eliminacion_tokens(texto):\n",
    "    # Procesar el texto con el objeto nlp\n",
    "    doc = nlp(texto)\n",
    "    # Lematizar el texto\n",
    "    lemas = [token.lemma_ for token in doc]\n",
    "    # Eliminar símbolos de puntuación y stopwords\n",
    "    tokens_filtrados = [token for token in lemas if token.isalpha() and token.lower() not in es_stopwords]\n",
    "    # Unir los tokens filtrados en un nuevo texto\n",
    "    texto_procesado = ' '.join(tokens_filtrados)\n",
    "\n",
    "    return texto_procesado\n",
    "\n",
    "def transform_format(val):\n",
    "    if val == 0:\n",
    "        return 255\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "\n",
    "def wordcloud_plot(mercadona_hacendado, nombre: str):\n",
    "  fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "  ### preprocesado\n",
    "  mercadona_hacendado[\"normalized\"] = mercadona_hacendado[\"tweets\"].apply(lambda x:eliminar_espacios(x))\n",
    "  mercadona_hacendado[\"normalized\"] = mercadona_hacendado[\"normalized\"].apply(lambda x:texto_to_lower(x))\n",
    "  mercadona_hacendado[\"normalized\"] = mercadona_hacendado[\"normalized\"].apply(lambda x: normalizar_tokens(x))\n",
    "  mercadona_hacendado[\"normalized\"] = mercadona_hacendado[\"normalized\"].apply(lambda x: lematizar_eliminacion_tokens(x))\n",
    "\n",
    "    \n",
    "  txt_cat0 = \",\".join(mercadona_hacendado[mercadona_hacendado.search=='mercadona'].normalized.to_list())\n",
    "  txt_cat1 = \",\".join(mercadona_hacendado[mercadona_hacendado.search=='hacendado'].normalized.to_list())\n",
    "\n",
    "  #mask\n",
    "\n",
    "  threshold = 128\n",
    "  mercadona_mask = np.array(Image.open('./data/Silver/logos/Mercadona.png').convert('L'))\n",
    "  mercadona_mask_resized = np.array(Image.fromarray(mercadona_mask).resize((mercadona_mask.shape[1]*3, mercadona_mask.shape[0]*3)))\n",
    "  mercadona_mask_binary =  (mercadona_mask_resized > threshold).astype(np.uint8) * 255\n",
    "\n",
    "  hacendado_mask = np.array(Image.open('./data/Silver/logos/hacendado.png').convert('L'))\n",
    "  hacendado_mask_resized = np.array(Image.fromarray(hacendado_mask).resize((hacendado_mask.shape[1]*3, hacendado_mask.shape[0]*3)))\n",
    "  hacendado_mask_binary = (hacendado_mask_resized > threshold).astype(np.uint8) * 255\n",
    "\n",
    "  #iniciamos Wordcloud\n",
    "\n",
    "  stopwords_personalizadas = set(es_stopwords)\n",
    "  palabras_quitar = ['mercadona', 'hacendado']  \n",
    "  stopwords_personalizadas.update(palabras_quitar)\n",
    "\n",
    "  wordcloud = WordCloud(background_color=\"white\", max_words=1000, stopwords=stopwords_personalizadas, mask=mercadona_mask_binary,\n",
    "                      normalize_plurals = True, random_state=2025, contour_width=10, contour_color=\"forestgreen\")\n",
    "\n",
    "\n",
    "  # Genera el wordcloud\n",
    "  wordcloud.generate(txt_cat0)\n",
    "  # Visualizalo en una imagen\n",
    "  wordcloud.to_image()\n",
    "  # Mostrar el gráfico con título\n",
    "  fig = plt.figure(figsize=(20, 12))\n",
    "  plt.subplot(2, 1, 1)\n",
    "  plt.imshow(wordcloud, interpolation='bilinear')\n",
    "  plt.axis(\"off\")  # Ocultar ejes\n",
    " # plt.title(f\"Clase Negativo  en {nombre}\", fontsize=10)\n",
    "  #plt.show()\n",
    "\n",
    "\n",
    "  #iniciamos Wordcloud\n",
    "  wordcloud = WordCloud(background_color=\"white\", max_words=1000, stopwords=stopwords_personalizadas, mask=hacendado_mask_binary,\n",
    "                      normalize_plurals = True, random_state=2025, contour_width=10, contour_color=\"black\")\n",
    "\n",
    "    \n",
    "  # Genera el wordcloud\n",
    "  wordcloud.generate(txt_cat1)\n",
    "  wordcloud.to_image()\n",
    "  # Mostrar el gráfico con título\n",
    "  #plt.figure(figsize=(16, 10))\n",
    "  plt.subplot(2, 1, 2)\n",
    "  plt.imshow(wordcloud, interpolation='bilinear')\n",
    "  plt.axis(\"off\")  # Ocultar ejes\n",
    "  #plt.title(f\"Clase Positiva  en {nombre}\", fontsize=10)  # Aquí colocas tu título\n",
    "  plt.show()\n",
    "\n",
    "  return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87cec5-268b-400b-9dfe-48a26a0a4922",
   "metadata": {},
   "outputs": [],
   "source": [
    "figura = wordcloud_plot(mercadona_hacendado, \"Datos Merged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764dfae-a793-4fec-aa51-358c41017c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "figura.set_size_inches(10, 6)  \n",
    "figura.savefig('./data/Gold/graph/wordcloud.png', dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
