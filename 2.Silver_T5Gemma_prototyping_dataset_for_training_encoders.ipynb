{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83682bfa-b853-4814-9f82-d9b15f1c541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n",
    "import torch\n",
    "from huggingface_hub import login\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "with open(\"HF_TOKEN.txt\", \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "login(token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a450506-84d8-4a1b-a07b-a7101e7deb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "#chunk archivo json con todo los productos de mercadona.\n",
    "\n",
    "def generar_chunks_para_vectorizar(ruta_archivo: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Carga el JSON y crea una lista de strings (chunks) para ser vectorizados,\n",
    "    combinando categoría, subcategoría y el nombre del producto.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(ruta_archivo, 'r', encoding='utf-8') as f:\n",
    "            datos: List[Dict] = json.load(f)\n",
    "        \n",
    "        chunks: List[str] = []\n",
    "        for categoria_principal in datos:\n",
    "            nombre_categoria = categoria_principal['name']\n",
    "            \n",
    "            for subcategoria in categoria_principal.get('subcategories', []):\n",
    "                nombre_subcategoria = subcategoria['name']\n",
    "                \n",
    "                for producto in subcategoria.get('products', []):\n",
    "                    chunks.append(f\"{nombre_categoria} : {nombre_subcategoria} : {producto}\")\n",
    "\n",
    "        return chunks\n",
    "    \n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(f\"Error al cargar el archivo JSON: {e}\")\n",
    "        return []\n",
    "\n",
    "chunks_a_vectorizar = generar_chunks_para_vectorizar('./data/Silver/mercadona_data.json')\n",
    "if not chunks_a_vectorizar:\n",
    "    print(\"No se pudieron generar los chunks. Saliendo...\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Se han generado {len(chunks_a_vectorizar)} chunks para vectorizar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee553e22-3c2c-40b8-9ffc-1be4fb1d5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "#carga embedding\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                 \n",
    "    bnb_4bit_quant_type=\"nf4\",        \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, \n",
    "    bnb_4bit_use_double_quant=True,   \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model_name_embedding = 'intfloat/multilingual-e5-large-instruct'  #\"Qwen/Qwen3-Embedding-0.6B\"  \n",
    "tokenizer_embedding = AutoTokenizer.from_pretrained(model_name_embedding)\n",
    "model_embedding = AutoModel.from_pretrained(model_name_embedding,\n",
    "                                            torch_dtype=torch.bfloat16,\n",
    "                                            quantization_config=bnb_config,\n",
    "                                           )\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_embedding.to(device)\n",
    "\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "dataloader = DataLoader(chunks_a_vectorizar, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "embeddings_array = []\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_texts in tqdm(dataloader, desc=\"Vectorizando batches\"):\n",
    "        batch_dict = tokenizer_embedding(\n",
    "            batch_texts,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "\n",
    "        outputs = model_embedding(**batch_dict)\n",
    "        embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "        embeddings_normalized = F.normalize(embeddings, p=2, dim=1)\n",
    "        \n",
    "        embeddings_array.append(embeddings_normalized.cpu())\n",
    "\n",
    "embeddings_tensor = torch.cat(embeddings_array, dim=0)\n",
    "\n",
    "embeddings_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbfc6e1-6363-44ed-9ce0-5785389fed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "# La instrucción   el modelo según la documentación\n",
    "def get_detailed_instruct(task_description: str, query: str) -> str:\n",
    "    return f'Instruct: {task_description}\\nQuery:{query}'\n",
    "\n",
    "def buscar_entradas_relevantes(\n",
    "    producto: str,\n",
    "    embeddings_db: torch.Tensor,\n",
    "    chunks: List[str],\n",
    "    top_k: int = 5\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Busca las entradas más similares al producto en la base de datos de embeddings.\n",
    "    \n",
    "    Args:\n",
    "        producto (str): El nombre del producto a buscar.\n",
    "        embeddings_db (torch.Tensor): El tensor con los embeddings de la base de datos.\n",
    "        chunks (List[str]): La lista original de textos que se vectorizaron.\n",
    "        top_k (int): El número de resultados más relevantes a devolver.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: Las k entradas más relevantes.\n",
    "    \"\"\"\n",
    "    # 1. Prepara la consulta con la instrucción\n",
    "    task = 'Given a product, retrieve relevant categories from a grocery store'\n",
    "    consulta_con_instruct = get_detailed_instruct(task, producto)\n",
    "    \n",
    "    # 2. Vectoriza la consulta\n",
    "    with torch.no_grad():\n",
    "        batch_dict = tokenizer_embedding(\n",
    "            [consulta_con_instruct],\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        ).to(device)\n",
    "        \n",
    "        outputs = model_embedding(**batch_dict)\n",
    "        embedding_producto = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "        embedding_producto_normalized = F.normalize(embedding_producto, p=2, dim=1).cpu()\n",
    "\n",
    "    # 3. Calcula la similitud del coseno entre la consulta y la base de datos\n",
    "    puntuaciones_similitud = torch.matmul(embedding_producto_normalized, embeddings_db.T)[0]\n",
    "    \n",
    "    # 4. Obtiene los índices de las top_k entradas más similares\n",
    "    indices_top_k = torch.topk(puntuaciones_similitud, k=top_k).indices.tolist()\n",
    "\n",
    "    # 5. Devuelve los chunks originales correspondientes a esos índices\n",
    "    entradas_encontradas = [chunks[i] for i in indices_top_k]\n",
    "    return entradas_encontradas\n",
    "\n",
    "\n",
    "def buscar_en_prompt(lista):\n",
    "    resultados = []\n",
    "    try:\n",
    "        for i, item in enumerate(lista.split(\"1:\")[1].split(\":\")):  \n",
    "            resultados.append(f\"estos son los resultados para : {item}\")\n",
    "            a = buscar_entradas_relevantes(producto=item, embeddings_db=embeddings_tensor, chunks=chunks_a_vectorizar, top_k = 10)\n",
    "            resultados.append(a)\n",
    "            resultados.append(\"Indeterminado : Indeterminado : Productos no listados\")\n",
    "    except:\n",
    "        resultados = \"Indeterminado : Indeterminado : Productos no listados\"\n",
    "    return resultados\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b24261-933f-4644-8aed-9a677adc2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df = pd.read_parquet('./data/Silver/Cleaned_data.parquet')\n",
    "\n",
    "\n",
    "### para hacer prototipado de las querys. \n",
    "#df = df.sample(n=20)\n",
    "\n",
    "\n",
    "###subset aleatorio pero manteniendo proporcion de busqueda mercadona-hacendado\n",
    "n = 10000\n",
    "df_balanceado = (df.groupby('search', group_keys=False).apply(lambda x: x.sample(n=n//2, random_state=69)))\n",
    "\n",
    "df = df_balanceado \n",
    "\n",
    "# indices_a_conservar = [ 301265, 152950 ]\n",
    "# df = df.loc[df.index.isin(indices_a_conservar)]\n",
    "# df\n",
    "\n",
    "\n",
    "model_name = \"google/t5gemma-9b-9b-ul2-it\"\n",
    "\n",
    "## Load the model T5-gemma\n",
    "# Configuración de la cuantificación de 4 bits\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,                 \n",
    "    bnb_4bit_quant_type=\"nf4\",        \n",
    "    bnb_4bit_compute_dtype=torch.bfloat16, \n",
    "    bnb_4bit_use_double_quant=True,   \n",
    ")\n",
    "\n",
    "\n",
    "## al tener dos GPU de 12 G tengo que dividir manualmente el modelo porque el \"auto\" lo fragmenta\n",
    "# y a la hora de generar el output genera error\n",
    "device_map = {\n",
    "    'model.encoder': 'cuda:0',\n",
    "    'model.decoder': 'cuda:1',\n",
    "    'lm_head': 'cuda:1',\n",
    "    'model.shared': 'cuda:0' \n",
    "}\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=device_map, ## Normalmente \"auto\" o cuda:0, cuda:1 \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d5e6e-fc12-467f-af4b-113a10113e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### querys secuenciales, el salto de query es para usar ese indice \n",
    "\n",
    "querys= [\n",
    "    \"Clasifica el sentimiento del siguiente texto como 'positivo', 'negativo' o 'neutral'. Considera que algunos mensajes están escritos con humor. Explica brevemente tu decisión en este formato:  Sentimiento: [tu clasificación]. Razón: [tu explicación en menos de 50 palabras].\",\n",
    "    #f\"Justifica brevemente, 10-20 palabras, el porqué se ha clasificado con este sentimiento o connotación  '{sentimiento}' este texto: \" ,\n",
    "    \n",
    "    \n",
    "    #\"Clasifica el sentimiento del siguiente texto en 'positivo', 'negativo' o 'neutral' y explica el porqué en una frase corta. Sigue este formato: 'Sentimiento: [tu clasificacion]. Razón: [tu explicacion]'. No excedas las 20 palabras en la razón. Ten en cuenta que son mensajes tipo tweet. Piensa paso a paso\",  \n",
    "    \"Clasifica el sentimiento del siguiente texto como 'positivo', 'negativo' o 'neutral'. Ten en cuenta que muchos mensajes son informales, sin puntuación, o escritos en mayúsculas. No asumas un tono emocional solo por eso. Detecta y considera humor, sarcasmo, ironía, exageraciones o contradicciones (por ejemplo: 'en verdad no', 'ya claro', 'sí pero no', uso excesivo de signos o mayúsculas). Determina el sentimiento real que transmite el mensaje. Considera como neutral todo mensaje que simplemente informe un hecho o dato sin mostrar emociones claras.  Explica brevemente tu decisión en este formato:  Sentimiento: [tu clasificación]. Razón: [tu explicación en menos de 50 palabras]. Piensa paso a paso antes de decidir.\",\n",
    "    \n",
    "    \n",
    "    \"Analiza si el texto contiene información personal (teléfono, dirección, DNI). Responde solo con 'SI' o 'NO'.\",\n",
    "\n",
    "    \n",
    "    #\"Analiza si el texto menciona un producto que pueda venderse en un supermercado, incluyendo alimentos, bebidas, productos de limpieza, artículos para el hogar, higiene o cualquier otro artículo. 'Mercadona' o 'Hacendado' no son productos, sino el nombre del supermercado o la marca. Si menciona un producto, responde solo con 'SI'; si no, responde 'NO'.\",\n",
    "    \"Analiza si el texto menciona un producto que pueda venderse en un supermercado, incluyendo alimentos, bebidas, productos de limpieza, artículos para el hogar, higiene personal, cosmética, maquillaje, skincare u otras categorías similares. Si menciona un producto o una categoría de productos, responde solo con 'SI'; si no, responde 'NO'.\",\n",
    "\n",
    "    \"Salto de query\", # para usar prompt custom \n",
    "    \n",
    "    #\"Analiza si el texto menciona uno o más productos o categorías que puedan venderse en un supermercado, incluyendo alimentos, bebidas, limpieza, hogar, higiene personal, cosmética, maquillaje, skincare u otros similares. 'Mercadona' y 'Hacendado' no son productos. Si menciona un producto o categoría, devuelve el nombre exacto tal como aparece en el texto, eliminando cualquier referencia a 'Mercadona' o 'Hacendado'. Si hay varios, usa el formato '1: Producto_1, 2: Producto_2'. Si no menciona ninguno, responde exactamente con 'No aplica'.\",\n",
    "    \n",
    "    #\"Analiza si el texto menciona uno o más productos o categorías de productos que puedan venderse en un supermercado. Esto incluye no solo artículos específicos como 'leche' o 'detergente', sino también categorías generales como 'skincare', 'cuidado de la piel', 'maquillaje', 'cosmética', 'higiene personal', 'productos de limpieza' o equivalentes. Considera sinónimos y términos en otros idiomas que signifiquen lo mismo. 'Mercadona' o 'Hacendado' no son productos. Si menciona uno o varios, responde con el nombre exacto tal como aparece en el texto (sin añadir 'de Mercadona', 'del Mercadona', 'de Hacendado' o 'del Hacendado'). Si hay varios, usa el formato '1: Producto_1, 2: Producto_2'. Si no menciona ninguno, responde exactamente con 'No aplica'.\",\n",
    "    #\"Extrae del texto productos o categorías de supermercado. Esto incluye no solo artículos específicos como 'leche' o 'detergente', sino también categorías generales como 'skincare', 'cuidado de la piel', 'maquillaje', 'cosmética', 'higiene personal', 'productos de limpieza' o equivalentes. Considera sinónimos y términos en otros idiomas que signifiquen lo mismo. 'Mercadona', 'Hacendado', 'mercadona' o 'hacendado' no son productos. responde con el nombre exacto tal como aparece en el texto (sin añadir 'de Mercadona', 'del Mercadona', 'de Hacendado' o 'del Hacendado'). Responde 'No aplica' si no hay productos. Si hay uno o varios, lista los nombres exactos tal como aparecen, en formato 1: Producto_1, 2: Producto_2.\",\n",
    "    \"\"\"Extrae del texto productos o categorías de supermercado.\n",
    "\n",
    "        Reglas y pasos a seguir:\n",
    "        \n",
    "        1. **Regla prioritaria antes de extraer**: \n",
    "           - Elimina de la consideración toda mención a nombres de tiendas, cadenas o marcas si no vienen acompañadas de un producto específico.\n",
    "           - Ejemplos: “Mercadona”, “Hacendado” no se consideran productos.\n",
    "           - Solo si aparece un producto junto a la marca se incluye (por ejemplo: “galletas Hacendado”).\n",
    "        \n",
    "        2. Lee el texto de entrada con atención.\n",
    "        \n",
    "        3. Identifica el producto de mercadona o hacendado:\n",
    "           - Incluye artículos específicos como “leche”, “detergente”, “pan integral”.\n",
    "           - Incluye categorías generales como “skincare”, “cuidado de la piel”, “maquillaje”, “cosmética”, “higiene personal”, “productos de limpieza”, o equivalentes.\n",
    "           - Considera sinónimos y términos en otros idiomas que signifiquen lo mismo.\n",
    "           - Considera sabores, colores y adjetivos inseparables como parte del producto, por ejemplo: “jamón serrano”, “patatas sabor jamón”, “donuts de chocolate”.\n",
    "           - No incluyas adjetivos sueltos que no sean parte inseparable del producto.\n",
    "        \n",
    "        4. No fragmentar productos compuestos:\n",
    "           - Si un producto está formado por varios elementos que aparecen juntos y funcionan como un solo producto, listarlo como una única entrada. Ejemplo: “conos de bacon y queso” → solo un producto.\n",
    "        \n",
    "        5. Excluir elementos que no sean productos o categorías reales:\n",
    "           - No incluir marcas, tiendas o cadenas sin producto específico.\n",
    "           - No incluir frases como “de Mercadona” o “de Hacendado”.\n",
    "           - No incluir menciones de productos usadas solo en sentido figurado.\n",
    "           - No incluir adjetivos, descriptores o calificativos que no formen parte inseparable del nombre del producto.\n",
    "        \n",
    "        6. Mantener el nombre exacto tal como aparece en el texto:\n",
    "           - No corregir, traducir o modificar.\n",
    "           - Respetar mayúsculas, minúsculas y ortografía original.\n",
    "        \n",
    "        7. Eliminar duplicados y genéricos si existen versiones más específicas:\n",
    "           - Si un producto está completamente contenido en otro más largo, mantener solo el más específico.\n",
    "           - Ejemplo: si aparecen “tinte” y “tinte pelirrojo”, incluir solo “tinte pelirrojo”.\n",
    "        \n",
    "        8. Formato de respuesta:\n",
    "           - Si no hay productos. Responde exactamente: No aplica\n",
    "           - Si hay uno o más productos. listarlos en formato:\n",
    "             1: Producto_1\n",
    "             2: Producto_2\n",
    "             3: Producto_3\n",
    "             (manteniendo el orden en el que aparecen en el texto).\n",
    "        \n",
    "        9. Paso final de control:\n",
    "           - Confirmar que:\n",
    "             - No hay marcas o tiendas solas.\n",
    "             - No hay duplicados.\n",
    "             - No hay versiones genéricas si hay una más específica.\n",
    "             \n",
    "         Ejemplo: \n",
    "         Texto: 'MADRE MIA, QUE BUENA ESTA LA NOCILLA DEL MERCADONA' \n",
    "         Respuesta:\n",
    "         1: Nocilla\n",
    "         \n",
    "         -Ahora analiza:\"\"\",\n",
    "    \n",
    "    \"Salto de query\", # para usar prompt custom \n",
    "    \"Salto de query\", # para usar prompt custom \n",
    "    \"Salto de query\", # para usar prompt custom \n",
    "    \"Salto de query\", # para usar prompt custom \n",
    "    \"Salto de query\",\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59da50-3aa6-4017-8174-1e0f90a49f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prompts y generacion \n",
    "\n",
    "df_resultado = pd.DataFrame()\n",
    "\n",
    "for documento in tqdm(df['tweets'], desc=\"Processing Tweets\"):\n",
    "    # print(\"===============================================\")\n",
    "    # print(\"===============================================\")\n",
    "    # print(\"===============================================\")\n",
    "    #print(documento)\n",
    "\n",
    "    # #dataframe temporal y listas temporales\n",
    "    temp_df = pd.DataFrame()\n",
    "    explica_sentimiento, explica_sentimiento_2, LOPD, integridad_mensaje, deteccion_producto, sentimiento_final, producto, sentimiento_producto, imagen_marca, categoria, comparativa_producto, comparativa_sentimiento_producto = [], [], [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "    \n",
    "    for i, user_query in enumerate(querys):     \n",
    "        # Crear prompt\n",
    "\n",
    "        ##para acelerar el procesado, se verifica si hay alggun producto detectado, igual en el i==6 \n",
    "        if i == 5 and deteccion_producto[-1].strip()  == 'NO':\n",
    "            producto.append('No aplica')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if i == 0 or i == 1 or i == 2 or i == 3 or i==5:     \n",
    "                prompt = [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": (\n",
    "                            \"Eres un analista experto en mensajes breves. Tu única tarea es extraer información explícita del mensaje.\\n\"\n",
    "                            \"Responde **solo** con el valor solicitado. No añadas introducciones, explicaciones, encabezados, ni texto adicional.\\n\"\n",
    "                            \"No uses formato, como negritas, cursivas o cualquier otro tipo de markdown.\\n\"\n",
    "                            \"Utiliza el formato específico de la pregunta (ej. 'SI'/'NO', 'positivo'/'negativo'/'neutral').\\n\"\n",
    "                            \"Responde siempre en español.\\n\"\n",
    "                            \"Esfuerzate al 100%.\\n\"\n",
    "                            \"Los resultados son muy importantes para mi.\\n\"\n",
    "                            f\"Tarea: {user_query}\\n\"\n",
    "                            f\"Texto: {documento}\"\n",
    "                        )\n",
    "                    }\n",
    "        \n",
    "                ]\n",
    "        \n",
    "        \n",
    "                #Generar respuesta\n",
    "                input_ids = tokenizer.apply_chat_template(prompt, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True)    \n",
    "                input_ids = {k: v.to('cuda:0') for k, v in input_ids.items()}\n",
    "                outputs = model.generate(**input_ids, max_new_tokens=100, do_sample=False) #determinista temperatura 0 y do_sample\n",
    "                response = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "                #print(response)\n",
    "\n",
    "            else:\n",
    "                #print('saltamos query list')\n",
    "                pass\n",
    "  \n",
    "            # Almacenar en la variable correspondiente\n",
    "            if i == 0:\n",
    "                explica_sentimiento.append(response)\n",
    "            elif i == 1:\n",
    "                explica_sentimiento_2.append(response)\n",
    "            elif i == 2:\n",
    "                LOPD.append(response)\n",
    "            elif i == 3:\n",
    "                deteccion_producto.append(response)\n",
    "            elif i == 5:\n",
    "                producto.append(response)\n",
    "            \n",
    "            elif i == 4:\n",
    "                prompt_desempate = [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"Eres un analista experto en mensajes breves. Tu única tarea es extraer información explícita del mensaje.\\n\"\n",
    "                        \"Responde **solo** con el valor solicitado. No añadas introducciones, explicaciones, encabezados, ni texto adicional.\\n\"\n",
    "                        \"No uses formato, como negritas, cursivas o cualquier otro tipo de markdown.\\n\"\n",
    "                        \"Utiliza el formato específico de la pregunta (ej. 'positivo'/'negativo'/'neutral').\\n\"\n",
    "                        \"Responde siempre en español.\\n\"\n",
    "                        \"Esfuerzate al 100%.\\n\"\n",
    "                        \"Los resultados son muy importantes para mi.\\n\"\n",
    "                        f\"Tarea: Debes desempatar la clasificación de sentimiento para el texto. El primer veredicto es '{explica_sentimiento}' y el segundo es '{explica_sentimiento_2}'. Analiza cuidadosamente el texto completo, y las justificaciones, la ironía, el humor o el sarcasmo son importantes para tomar una decisión. Piensa paso a paso de forma interna pero no muestres tu razonamiento. Responde únicamente con una sola palabra: 'positivo', 'negativo' o 'neutral'. No añadas explicaciones, ejemplos ni justificaciones. Texto a analizar: '{documento}'.\"\n",
    "                    )}]\n",
    "    \n",
    "    \n",
    "                input_ids = tokenizer.apply_chat_template(prompt_desempate, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True)    \n",
    "                input_ids = {k: v.to('cuda:0') for k, v in input_ids.items()}\n",
    "                outputs = model.generate(**input_ids, max_new_tokens=10, do_sample=False) \n",
    "                response_desempate = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "                \n",
    "                #print(response_desempate)\n",
    "    \n",
    "                sentimiento_final.append(response_desempate)\n",
    "                 \n",
    "            elif i == 6:\n",
    "                \n",
    "                if deteccion_producto[-1].strip()  == 'NO':\n",
    "                    sentimiento_producto.append('NO')\n",
    "    \n",
    "                else:\n",
    "                    prompt_producto = [{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": (\n",
    "                            \"Eres un analista experto en mensajes breves. Tu única tarea es extraer información explícita del mensaje.\\n\"\n",
    "                            \"Responde **solo** con el valor solicitado. No añadas introducciones, explicaciones, encabezados, ni texto adicional.\\n\"\n",
    "                            \"No uses formato, como negritas, cursivas o cualquier otro tipo de markdown.\\n\"\n",
    "                            \"Utiliza el formato específico de la pregunta (ej. 'SI'/'NO').\\n\"\n",
    "                            \"Responde siempre en español.\\n\"\n",
    "                            \"Esfuerzate al 100%.\\n\"\n",
    "                            \"Los resultados son muy importantes para mi.\\n\"\n",
    "                            \n",
    "                            f\"\"\"Determina si las justificaciones del sentimiento se refieren al producto '{producto}'.\n",
    "                            \n",
    "                            -Instrucciones:\n",
    "                            1. Lee el texto de entrada y las justificaciones de sentimiento dadas.\n",
    "                            2. Analiza cada justificación:\n",
    "                               - Determina si describen una emoción causada directamente por el producto.\n",
    "                               - Se consideran válidas emociones como gusto, asco, placer, amor, odio, decepción, disgusto, satisfacción, etc., cuando son provocadas por el producto en sí.\n",
    "                               - Ignora emociones originadas por resistirse al producto, evitarlo o mencionarlo solo en contexto (como parte de una rutina o anécdota).\n",
    "                               - La necesidad puede estar motivada por una situación negativa, pero eso **no indica una emoción causada por el producto** si no ha sido utilizado o evaluado aún.\n",
    "                               -Las justificaciones dadas explican únicamente el sentimiento percibido en el texto, no si este está relacionado directamente con el producto.\n",
    "                               - Tu tarea es decidir si ese sentimiento ha sido causado directamente por el producto.\n",
    "                            3. Recuerda: 'mercadona', 'Mercadona', 'hacendado' o 'Hacendado' **no son productos por sí solos**.\n",
    "                               - Pero si se menciona un producto real acompañado de estos términos (ej. “galletas de Hacendado”), **sí se considera válido**.\n",
    "                            4. Regla de decisión:\n",
    "                               - Si ambas justificaciones se refieren claramente al producto y la emoción es causada directamente por él, responde: SI.\n",
    "                               - En cualquier otro caso, responde: NO.\n",
    "                            5. Formato:\n",
    "                               - Solo responde con SI o NO, sin comillas ni explicaciones.\n",
    "\n",
    "                            -Ejemplos:\n",
    "                            \n",
    "                            Ejemplo 1:\n",
    "                            Producto: '1: arroz 2: alga nori'  \n",
    "                            Texto: 'Quiero hacer sushi pero @Mercadona tuvo la genial idea de quitar el arroz y el alga nori.'\n",
    "                            Justificación 1: 'Sentimiento: negativo. Razón: El usuario expresa frustración por la falta de ingredientes para hacer sushi, lo que denota un sentimiento negativo.'\n",
    "                            Justificación 2: 'Sentimiento: negativo. Razón: El mensaje expresa frustración por la falta de ingredientes para hacer sushi, atribuyéndola a una \"genial idea\" de Mercadona, lo que implica sarcasmo y enfado.'\n",
    "                            respuesta: SI\n",
    "\n",
    "                            Ejemplo 2:\n",
    "                            Producto: '1: lentejas precocinadas'\n",
    "                            Texto: 'Las lentejas precocinadas me dieron un asco horrible. No pude ni terminarlas.'\n",
    "                            Justificación 1: 'Sentimiento: negativo. Razón: El autor manifiesta asco y rechazo por la experiencia al consumir las lentejas.'\n",
    "                            Justificación 2: 'Sentimiento: negativo. Razón: El mensaje refleja disgusto directo tras probar el producto.'\n",
    "                            Respuesta: SI\n",
    "                            \n",
    "                            Ejemplo 3:\n",
    "                            Producto: '1: bollería'\n",
    "                            Texto: Ese aire de superioridad con el que paseo por los pasillos de bollería del Mercadona, sin coger nada.'\n",
    "                            Justificación 1: 'Sentimiento: positivo. Razón: El autor se siente satisfecho por su autocontrol y capacidad de resistirse a la tentación.'\n",
    "                            Justificación 2: 'Sentimiento: positivo. Razón: El mensaje transmite orgullo personal vinculado al comportamiento del hablante.'\n",
    "                            Respuesta: NO\n",
    "                            \n",
    "                            Ejemplo 4:\n",
    "                            Producto: '1: Coca Cola Zero'\n",
    "                            Texto: 'No seré yo quien se meta con Mercadona por poner los precios que le de la gana pero que no engañen. Hasta hace cosa de semana y media compraba un pack de Cocal Cola Zero por 3,7... el pico exacto no me acuerdo. De repente lo subieron a 4€ hace unos días.'                          \n",
    "                            Justificación 1: 'Sentimiento: negativo. Razón: El usuario expresa su descontento por el aumento de precio de un producto en Mercadona, utilizando un tono crítico.' \n",
    "                            Justificación 2: 'Sentimiento: negativo. Razón: El usuario expresa su descontento por el aumento de precio de un producto en Mercadona, utilizando términos como \"no engañen\" y \"de repente\".'\n",
    "                            Respuesta: SI\n",
    "                            \n",
    "                            Ejemplo 5: \n",
    "                            Producto: '1: repelente de mosquitos' \n",
    "                            Texto: 'Tercera noche consecutiva de caza de mosquitos. Esto mañana se acaba porque pienso comprar todo lo habido y por haber que repela a los mosquitos de Mercadona. Así que @Mercadona prepara mercancía que voy.'\n",
    "                            Justificación 1: 'Sentimiento: negativo. Razón: El usuario se queja de la caza de mosquitos durante tres noches consecutivas y expresa su intención de comprar repelentes.'\n",
    "                            Justificación 2: 'Sentimiento: negativo. Razón: El mensaje expresa frustración por las mosquitos y la necesidad de comprar repelentes, lo que indica una experiencia negativa.'\n",
    "                            Respuesta: NO\n",
    "                            \n",
    "                            -Ahora analiza el siguiente caso:\n",
    "                            \n",
    "                            Producto: '{producto}'\n",
    "                            Texto: '{documento}'\n",
    "                            Justificación 1: '{explica_sentimiento}'\n",
    "                            Justificación 2: '{explica_sentimiento_2}'\n",
    "                            Respuesta:\"\"\"\n",
    "        \n",
    "                        )}]\n",
    "        \n",
    "                    input_ids = tokenizer.apply_chat_template(prompt_producto, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True)    \n",
    "                    input_ids = {k: v.to('cuda:0') for k, v in input_ids.items()}\n",
    "                    outputs = model.generate(**input_ids, max_new_tokens=7, do_sample=False) \n",
    "                    response_producto = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "        \n",
    "                    #print(response_producto)\n",
    "        \n",
    "                    sentimiento_producto.append(response_producto)\n",
    "    \n",
    "            elif i == 7:\n",
    "                prompt_marca = [{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"Eres un analista de mensajes breves experto en marketing. Tu única tarea es extraer información explícita del mensaje.\\n\"\n",
    "                        \"Responde **solo** con el valor solicitado. No añadas introducciones, explicaciones, encabezados, ni texto adicional.\\n\"\n",
    "                        \"No uses formato, como negritas, cursivas o cualquier otro tipo de markdown.\\n\"\n",
    "                        \"Utiliza el formato específico de la pregunta (ej. 'SI'/'NO').\\n\"\n",
    "                        \"Responde siempre en español.\\n\"\n",
    "                        \"Esfuerzate al 100%.\\n\"\n",
    "                        \"Los resultados son muy importantes para mi.\\n\"\n",
    "\n",
    "                        f\"\"\"Determina si las justificaciones de sentimiento se refieren directamente a la imagen, reputación o percepción de la marca 'Mercadona' o 'Hacendado' en el texto.\n",
    "                        \n",
    "                        Instrucciones paso a paso:\n",
    "                        1. Lee el texto de entrada y las justificaciones de sentimiento dadas.\n",
    "                        \n",
    "                        2. Analiza el primer sentimiento y su justificación.\n",
    "                           - Determina si se refiere directamente a la imagen, reputación o percepción de la cadena de supermercado 'Mercadona' o la marca de alimentos 'Hacendado'.\n",
    "                           - Considera menciones literales, sinónimos, referencias implícitas o alusiones indirectas a la imagen de marca.\n",
    "                       \n",
    "                        3. Analiza el segundo sentimiento y su justificación con el mismo criterio.\n",
    "                       \n",
    "                        4. Regla de decisión:\n",
    "                           - Si una o ambas justificaciones se refieren claramente a la imagen de mercadona o percepción de la marca hacendado, responde exactamente: SI.\n",
    "                           - Si no lo hacen, responde exactamente: NO.\n",
    "                       \n",
    "                        5. Formato de respuesta:\n",
    "                           - Responde únicamente con SI o NO, sin comillas ni explicaciones.\n",
    "                           - El razonamiento debe hacerse internamente, pero no mostrarse en la salida final.   \n",
    "\n",
    "                        -Ejemplos:\n",
    "                        \n",
    "                        Ejemplo 1:\n",
    "                        Texto:'callate zorra te bebes vodka de 3 euros del Mercadona, la vacuna no te va a hacer nada'\n",
    "                        Primer Sentimiento y su justificación: 'Sentimiento: negativo. Razón: El mensaje es agresivo y despectivo, utilizando insultos y amenazas. No hay indicio de humor o positivismo.'                        \n",
    "                        Segundo sentimiento y su justificación: 'Sentimiento: negativo. Razón: El mensaje es agresivo y despectivo, utilizando insultos y un tono sarcástico.'\n",
    "                        Respuesta: 'NO'\n",
    "\n",
    "                        Ejemplo 2:\n",
    "                        Texto: 'Al Mercadona le han pillado con el carrito del helado. Los plátanos de canarias los llegué a ver a 3.15€ a unos meses, hoy 2.79€. No venderían uno teniendo las bananas a casi un tercio de precio.'\n",
    "                        Primer Sentimiento y su justificación: 'Sentimiento: negativo. Razón: El mensaje expresa frustración por el precio de los plátanos de Canarias, a pesar de que han bajado, ya que aún son más caros que las bananas.' \n",
    "                        Segundo Sentimiento y su justificación: 'Sentimiento: negativo. Razón: El mensaje expresa sorpresa y desconfianza hacia la bajada de precio de los plátanos, sugiriendo que es una estrategia para vender más plátanos de Canarias.' \n",
    "                        Respuesta: 'SI'\n",
    "\n",
    "                        Ejemplo 3:\n",
    "                        Texto:'odio que cambien las cosas de sitio en el mercadona cada 2x3, doy vueltas como una tonta'\n",
    "                        Primer Sentimiento y su justificación: 'Sentimiento: negativo. Razón: El mensaje expresa frustración y molestia por el cambio constante de productos en el supermercado, lo que genera una experiencia negativa para la persona.' \n",
    "                        Segundo Sentimiento y su justificación:  'Sentimiento: negativo. Razón: La frase expresa una fuerte desaprobación por el cambio constante de productos en el supermercado, lo que genera frustración y molestia en la persona.' \n",
    "                        Respuesta: 'SI'\n",
    "\n",
    "                        Ejemplo 4:\n",
    "                        Texto: 'En fin... El Mercadona'\n",
    "                        Primer Sentimiento y su justificación: 'Sentimiento: neutral. Razón: El mensaje expresa una conclusión, pero no una opinión positiva o negativa sobre Mercadona.'                    \n",
    "                        Segundo Sentimiento y su justificación: 'Sentimiento: negativo. Razón: El mensaje expresa una frustración o cansancio, como si el usuario estuviera harto de Mercadona.'\n",
    "                        Respuesta: 'SI'\n",
    "                        \n",
    "                        -Ahora analiza el siguiente caso:\n",
    "                        Texto: '{documento}'\n",
    "                        Primer Sentimiento y su justificación: '{explica_sentimiento}'\n",
    "                        Segundo Sentimiento y su justificación: '{explica_sentimiento_2}'\n",
    "                        Respuesta: \"\"\"\n",
    "     \n",
    "                    )}]\n",
    "    \n",
    "    \n",
    "                input_ids = tokenizer.apply_chat_template(prompt_marca, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True)    \n",
    "                input_ids = {k: v.to('cuda:0') for k, v in input_ids.items()}\n",
    "                outputs = model.generate(**input_ids, max_new_tokens=7, do_sample=False) \n",
    "                response_marca= tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "    \n",
    "                #print(response_marca)\n",
    "    \n",
    "                imagen_marca.append(response_marca)          \n",
    "\n",
    "\n",
    "            elif i == 8:\n",
    "                if deteccion_producto[-1].strip()  == 'NO' or sentimiento_producto[-1].strip()  == 'NO':\n",
    "                    categoria.append('No aplica') \n",
    "                else:               \n",
    "                    prompt_categoria = [{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": (\n",
    "                        f\"\"\"Eres un clasificador de productos.\n",
    "                            Responde **solo** con la categoría y subcategoría exactas de la lista dada.\n",
    "                            No añadas introducciones, explicaciones, encabezados, ni texto adicional.\n",
    "                            No uses formato como negritas, cursivas o cualquier tipo de markdown.\n",
    "                            \n",
    "                            Tu tarea es clasificar el/los siguientes producto(s) indicados en 'Objeto',\n",
    "                            basándote en la lista de referencia y usando también la información de 'CONTEXTO'.\n",
    "                            \n",
    "                            ---\n",
    "                            **Instrucciones:**\n",
    "                            \n",
    "                            1.  Lee el 'Objeto' para identificar el producto y el 'CONTEXTO' para obtener pistas adicionales.\n",
    "                            2.  **PRIORIDAD DEL CONTEXTO:** El **CONTEXTO** tiene prioridad absoluta sobre el nombre del producto o la lista de referencia. Si el contexto contiene información clave (ej. \"en farmacia\", \"supermercado\", \"marca X\"), úsala como la pista principal para la clasificación, incluso si otros productos de la lista parecen similares por el nombre.\n",
    "                            3.  Usa la información del contexto para corregir errores o ambigüedades en el nombre del producto.\n",
    "                            4.  **Encuentra la coincidencia más cercana:** De toda la lista de referencia, busca la línea que contenga el nombre del producto o su variante más parecida. Esta será tu clasificación principal.\n",
    "                            5.  Busca la categoría y subcategoría que mejor se ajusten al producto identificado en la lista de referencia.\n",
    "                                -La lista de referencia sigue el siguiente formato CATEGORIAS : SUBCATEGORIAS : PRODUCTOS\n",
    "                                \n",
    "                            6.  Si el producto podría encajar en varias categorías, elige la más probable **según el CONTEXTO**.\n",
    "                            7.  Si el producto no aparece o no encaja en ninguna categoría, responde con: Indeterminado : Indeterminado.\n",
    "                            8.  Si se están comparando dos productos entre si, asume que son de la misma categoría y asignalos al más claro. \n",
    "                            9.  Devuelve la respuesta en este formato, manteniendo el orden original de aparición:\n",
    "                                1: Categoria_1 : Subcategoria\n",
    "                                2: Categoria_2 : Subcategoria\n",
    "                                ...\n",
    "                            10.  No incluyas comillas, texto adicional ni inventes categorías.\n",
    "                            11. Devuelve las categorías y subcategorías de manera completa. Si encuentras la categoría pero hay varias subcategorías posibles, elige la más probable para el producto en función del **CONTEXTO**.\n",
    "\n",
    "                            Ejemplo 1:\n",
    "                            Objeto:\n",
    "                            \\n                            \\'[\\'1: Bephantol\\\\n2: vaselina \\\\n\\']\\'\\n                            \n",
    "                            CONTEXTO:\n",
    "                            'Bephantol 8,95 en farmacia, vaselina 2 en mercadona, yo no me la juego'\n",
    "                            Lista de referencia (Categoría : Subcategoría : Producto):\n",
    "                            '[\\'estos son los resultados para :  Bephantol\\\\n2\\', [\\'Azúcar, caramelos y chocolate : Azúcar y edulcorante : Edulcorante Eritritol y Sucralosa Hacendado\\', \\'Cuidado facial y corporal : Higiene bucal : Dentífrico Bicarbonato blanqueador Deliplus\\', \\'Azúcar, caramelos y chocolate : Azúcar y edulcorante : Edulcorante en pastillas sacarina Hacendado\\', \\'Azúcar, caramelos y chocolate : Chicles y caramelos : Caramelos eucaliptus mentol Respiral Halls\\', \\'Cuidado facial y corporal : Gel y jabón de manos : Gel de baño avena Deliplus piel sensible\\', \\'Cuidado facial y corporal : Gel y jabón de manos : Gel aceite de baño Deliplus piel atópica\\', \\'Cuidado facial y corporal : Gel y jabón de manos : Jabón de manos avena Deliplus líquido\\', \\'Azúcar, caramelos y chocolate : Azúcar y edulcorante : Edulcorante líquido sacarina Hacendado\\', \\'Cuidado facial y corporal : Higiene bucal : Dentífrico Blanqueador Bicarbonato Signal\\', \\'Azúcar, caramelos y chocolate : Azúcar y edulcorante : Edulcorante granulado stevia Hacendado\\'], \\'Indeterminado : Indeterminado : Productos no listados\\', \\'estos son los resultados para :  vaselina \\\\n\\', [\\'Maquillaje : Labios : Vaselina hidratante Deliplus\\', \\'Cuidado facial y corporal : Gel y jabón de manos : Gel de baño vainilla y miel Deliplus piel normal\\', \\'Maquillaje : Labios : Vaselina perfumada para labios Deliplus frambuesa\\', \\'Cuidado facial y corporal : Gel y jabón de manos : Esponja de baño flor Deliplus exfoliación suave\\', \\'Cuidado facial y corporal : Higiene íntima : Toallitas íntimas Deliplus monodosis\\', \\'Cuidado facial y corporal : Perfume y colonia : Agua de colonia Deliplus Floral Infusion\\', \\'Fitoterapia y parafarmacia : Parafarmacia : Vaselina hidratante Deliplus\\', \\'Cuidado facial y corporal : Gel y jabón de manos : Esponja de baño suave Deliplus\\', \\'Cuidado facial y corporal : Gel y jabón de manos : Jabón de manos avena Deliplus líquido\\', \\'Cuidado facial y corporal : Gel y jabón de manos : Esponja de baño rizo suave Deliplus\\'], \\'Indeterminado : Indeterminado : Productos no listados\\']'                  \n",
    "                           \n",
    "                            Respuesta:\n",
    "                            1: Fitoterapia y parafarmacia : Parafarmacia\n",
    "                            2: Fitoterapia y parafarmacia : Parafarmacia\n",
    "                            \n",
    "\n",
    "                            Ahora analiza el siguiente caso:\n",
    "                            Objeto:\n",
    "                            '{producto}'\n",
    "                            CONTEXTO:\n",
    "                            '{documento}'\n",
    "                            Lista de referencia (Categoría : Subcategoría : Producto):\n",
    "                            {buscar_en_prompt(producto[-1])}\n",
    "                    \n",
    "                            Respuesta:\"\"\"\n",
    "                        )}]\n",
    "        \n",
    "                    input_ids = tokenizer.apply_chat_template(prompt_categoria, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True)    \n",
    "                    input_ids = {k: v.to('cuda:0') for k, v in input_ids.items()}\n",
    "                    outputs = model.generate(**input_ids, max_new_tokens=50, do_sample=False) \n",
    "                    response_categoria = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "        \n",
    "                    #print(response_categoria)\n",
    "        \n",
    "                    categoria.append(response_categoria)       \n",
    "\n",
    "            elif i == 9:\n",
    "                if deteccion_producto[-1].strip()  == 'NO' or sentimiento_producto[-1].strip()  == 'NO':\n",
    "                    comparativa_producto.append('No aplica') \n",
    "                else:\n",
    "                    prompt_comparativa_producto = [{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": (\n",
    "                            \"Eres un analista experto en mensajes breves. Tu única tarea es extraer información explícita del mensaje.\\n\"\n",
    "                            \"Responde **solo** con el valor solicitado. No añadas introducciones, explicaciones, encabezados, ni texto adicional.\\n\"\n",
    "                            \"No uses formato, como negritas, cursivas o cualquier otro tipo de markdown.\\n\"\n",
    "                            \"Utiliza el formato específico.\\n\"\n",
    "                            \"Esfuerzate al 100%.\\n\"\n",
    "                            \"Los resultados son muy importantes para mi.\\n\"\n",
    "    \n",
    "                         f\"\"\"Determina si en el texto se están comparando productos entre productos de Mercadona o de la marca Hacendado y otras marcas y posibles competidores.\n",
    "\n",
    "                            -Instrucciones:\n",
    "                            1. Detectar comparación: Lee el texto y comprueba si se mencionan al menos dos productos en 'Producto'.\n",
    "                            2. Determinar si existe una comparativa entre productos:\n",
    "                               - para ello usa coomo contexto  el 'Texto' y la 'Justificación 1' y la 'Justificación 2' para determinar el sentimiento hacia un producto de mercadona o hacendado que se este comparando con otro.        \n",
    "                            3. Regla final:\n",
    "                               - Si se detecta comparación y uno de los productos es de Mercadona/Hacendado responde con 'SI' o 'NO'.\n",
    "                            4. Formato de respuesta:\n",
    "                               - Devuelve solo una de estas opciones: SI o NO.\n",
    "                               - No añadas explicaciones ni texto adicional.\n",
    "                            \n",
    "                            -Ejemplos:\n",
    "                            \n",
    "                            Ejemplo 1:\n",
    "                            Producto: '1: Bephantol 2: vaselina'\n",
    "                            Texto: 'Bephantol 8,95 en farmacia, vaselina 2 en Mercadona, yo no me la juego'\n",
    "                            Justificación 1: 'Sentimiento: negativo. Razón: El mensaje expresa una preferencia por la vaselina por ser más económica que el Bephantol, lo que implica una desaprobación del precio del Bephantol.'\n",
    "                            Justificación 2: 'Sentimiento: negativo. Razón: El mensaje expresa una preferencia clara por la vaselina por su bajo precio, implicando que el Bephantol es caro y no vale la pena.'\n",
    "                            Respuesta: SI\n",
    "                 \n",
    "                            -Ahora analiza el siguiente caso:\n",
    "                            \n",
    "                            Producto: '{producto}'\n",
    "                            Texto: '{documento}'\n",
    "                            Justificación 1: '{explica_sentimiento}'\n",
    "                            Justificación 2: '{explica_sentimiento_2}'\n",
    "                            Respuesta:\"\"\"\n",
    "        \n",
    "                        \n",
    "                 )}]\n",
    "        \n",
    "        \n",
    "                    input_ids = tokenizer.apply_chat_template(prompt_comparativa_producto, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True)    \n",
    "                    input_ids = {k: v.to('cuda:0') for k, v in input_ids.items()}\n",
    "                    outputs = model.generate(**input_ids, max_new_tokens=50, do_sample=False) \n",
    "                    response_comparativa_producto = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "        \n",
    "                    #print(response_comparativa_producto)\n",
    "        \n",
    "                    comparativa_producto .append(response_comparativa_producto)       \n",
    "\n",
    "\n",
    "            elif i == 10 :\n",
    "                if  comparativa_producto[-1].strip()  == 'NO' or comparativa_producto[-1].strip() == 'No aplica':\n",
    "                    comparativa_sentimiento_producto.append('No aplica') \n",
    "                else:\n",
    "                    prompt_comparativa_sentimiento_producto = [{\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": (\n",
    "                            \"Eres un experto en mensajes breves. Tu única tarea es extraer la información solicitada del mensaje.\\n\"\n",
    "                            \"Responde **solo** con el valor solicitado. No añadas introducciones, explicaciones, encabezados, ni texto adicional.\\n\"\n",
    "                            \"No uses formato, como negritas, cursivas o cualquier otro tipo de markdown.\\n\"\n",
    "                            \"Utiliza el formato específico.\\n\"\n",
    "                            \"Esfuerzate al 100%.\\n\"\n",
    "                            \"Los resultados son muy importantes para mi.\\n\"\n",
    "                            f\"\"\" valora el producto de mercadona o hacendado respecto a producto que se compara. \n",
    "                               - Instrucciones:\n",
    "                                    1. Determina cuál es el producto de la marca mercadona o hacendado.\n",
    "                                    2. valora el producto de mercadona o hacendado respecto a su competidor. \n",
    "                                        - Respuestas posibles: positivo, negativo o neutral.\n",
    "                                    3. Formato de respuesta:\n",
    "                                        - Producto de mercadona o hacendado : valoracion del producto respecto a la competencia. ej: yogur de stracciatella : positivo\n",
    "                            \n",
    "                            Texto: '{documento}'\n",
    "                            Respuesta:\"\"\"\n",
    "\n",
    "                            )}]\n",
    "\n",
    "            \n",
    "                    \n",
    "                    input_ids = tokenizer.apply_chat_template(prompt_comparativa_sentimiento_producto, return_tensors=\"pt\", return_dict=True, add_generation_prompt=True)    \n",
    "                    input_ids = {k: v.to('cuda:0') for k, v in input_ids.items()}\n",
    "                    outputs = model.generate(**input_ids, max_new_tokens=50, do_sample=False) \n",
    "                    response_comparativa_sentimiento_producto = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
    "\n",
    "                    #print(\"COMPARATIVA\")\n",
    "                    #print(limpiar_numeros(producto[-1]))\n",
    "                    #print(response_comparativa_sentimiento_producto)\n",
    "        \n",
    "                    comparativa_sentimiento_producto.append(response_comparativa_sentimiento_producto)       \n",
    "\n",
    "\n",
    "    \n",
    "    # resultados linea a dataframe\n",
    "    temp_df['explica_sentimiento'] = explica_sentimiento\n",
    "    temp_df['explica_sentimiento_2'] = explica_sentimiento_2\n",
    "    temp_df['sentimiento_final'] = sentimiento_final  ###\n",
    "    temp_df['proteccion_datos'] = LOPD\n",
    "    temp_df['deteccion_producto'] = deteccion_producto ###\n",
    "    temp_df['producto'] = producto\n",
    "    temp_df['sentimiento_producto'] = sentimiento_producto ####\n",
    "    temp_df['categoria'] = categoria\n",
    "    temp_df['comparativa_producto'] = comparativa_producto \n",
    "    temp_df['comparativa_sentimiento'] = comparativa_sentimiento_producto\n",
    "    temp_df['imagen_marca'] = imagen_marca ###\n",
    "\n",
    "\n",
    "    # Añadir al DataFrame general\n",
    "    df_resultado = pd.concat([df_resultado, temp_df], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e0619-5a7d-443b-b8ed-de9260ab06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#función de limpieza de resultados del LLM\n",
    "def clean_cell(text):\n",
    "    return text.split('\\n')[0]\n",
    "\n",
    "columns = ['proteccion_datos', 'deteccion_producto','sentimiento_final', 'sentimiento_producto','imagen_marca', 'comparativa_producto', 'comparativa_sentimiento']  #'producto',\n",
    "\n",
    "\n",
    "#aplicar\n",
    "for col in df_resultado[columns]:\n",
    "    df_resultado[col] = df_resultado[col].apply(clean_cell)\n",
    "\n",
    "\n",
    "\n",
    "#df_resultado['producto'] = df_resultado['producto'].str.split(\"\\n\")\n",
    "df_resultado['producto'] = df_resultado['producto'].str.replace(\"\\n\", \" \")\n",
    "df_resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fc70f-556b-4b4f-a437-699a96911a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultado['deteccion_producto'].value_counts()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c6fff-623e-4ce6-80a0-76226b7a7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_LLM = pd.concat([df.reset_index(), df_resultado], axis=1)\n",
    "#df_final_LLM.to_excel('.xlsx')\n",
    "df_final_LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9015629f-ef10-4409-8bca-d266aa4f2361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_LLM.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54657da-e9c0-40ff-bf71-0de8bdf2cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_LLM.describe(exclude='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f96cab7-6569-4f5b-b785-b56140d4496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista=[ 'sentimiento_final', 'search', 'proteccion_datos', 'deteccion_producto', 'sentimiento_producto', 'comparativa_producto', 'imagen_marca' ]\n",
    "\n",
    "for i in df_final_LLM[lista]:\n",
    "  print('=================')\n",
    "  print(df_final_LLM[i].value_counts())\n",
    "  print('=================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8624e9-c8b9-4165-bb08-cf777fd9177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limp = df_final_LLM['tweets'][df_final_LLM['proteccion_datos'].str.upper().astype(str).str.strip() == 'SI']\n",
    "\n",
    "for i in df_limp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f01786-92c6-4ada-8d2f-752a69af478b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ver los resultados de sentimiento_final  y arreglarlos\n",
    "\n",
    "df_limp = df_final_LLM['tweets'][df_final_LLM['sentimiento_final'] == 'sarcástico']\n",
    "\n",
    "for i in df_limp:\n",
    "    print(i)\n",
    "    \n",
    "\n",
    "df_limp = df_final_LLM.loc[df_final_LLM['sentimiento_final'] == 'sarcástico', ['tweets']]\n",
    "\n",
    "resultado = resultado = pd.merge(\n",
    "    df_limp,\n",
    "    df_final_LLM,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95dd39-9fce-4555-bb9b-28d9261a5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limp = df_final_LLM['tweets'][df_final_LLM['sentimiento_final'] == 'irónico']\n",
    "\n",
    "for i in df_limp:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae44f48-7036-4bcc-b7a5-f143f172845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def limpiar_sarcastico(df):\n",
    "    def extraer_sentimiento(row):\n",
    "        if row['sentimiento_final'] == 'sarcástico':\n",
    "            # Buscar patrón 'Sentimiento: <valor>.'\n",
    "            match = re.search(r\"Sentimiento:\\s*(\\w+)\\.\", str(row['explica_sentimiento_2']))\n",
    "            if match:\n",
    "                return match.group(1).lower()  # Devuelve el sentimiento en minúscula\n",
    "            else:\n",
    "                return row['sentimiento_final'] \n",
    "        else:\n",
    "            return row['sentimiento_final']\n",
    "    \n",
    "    df['sentimiento_final'] = df.apply(extraer_sentimiento, axis=1)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abff9719-1dc5-4563-b9c0-2c7cbfb198ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_LLM['sentimiento_final'] = df_final_LLM['sentimiento_final'].str.lower().astype(str).str.strip()\n",
    "df_final_LLM['sentimiento_final']  = df_final_LLM['sentimiento_final'] .str.replace('negative', 'negativo')\n",
    "df_final_LLM['sentimiento_final']  = df_final_LLM['sentimiento_final'] .str.replace('posiivo', 'positivo')\n",
    "df_final_LLM['sentimiento_final']  = df_final_LLM['sentimiento_final'] .str.replace('positivio', 'positivo')\n",
    "df_final_LLM['sentimiento_final']  = df_final_LLM['sentimiento_final'] .str.replace('irónico', 'negativo')\n",
    "\n",
    "df_final_LLM = limpiar_sarcastico(df_final_LLM)\n",
    "\n",
    "df_final_LLM['sentimiento_producto'] = df_final_LLM['sentimiento_producto'].str.upper().astype(str).str.strip()\n",
    "df_final_LLM['deteccion_producto'] = df_final_LLM['deteccion_producto'].str.replace('.', '', regex=False)\n",
    "\n",
    "#df.loc[[888,1072 ],'sentimiento_final'] =  ['positivo' , 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1bcc5-ba12-40f8-a7b3-93dcd53d6645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d02fdf-4c7b-43dd-afd3-d5889bd98f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista=[ 'sentimiento_final', 'search', 'proteccion_datos', 'deteccion_producto', 'sentimiento_producto', 'comparativa_producto', 'imagen_marca' ]\n",
    "\n",
    "for i in df_final_LLM[lista]:\n",
    "  print('=================')\n",
    "  print(df_final_LLM[i].value_counts())\n",
    "  print('=================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe39970c-dca3-40be-a932-0be310612fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_final_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6295a-471e-46da-995f-7473aa07fecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_LLM = df_final_LLM[df_final_LLM['proteccion_datos'].str.upper().str.strip() != 'SI']\n",
    "len(df_final_LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ed981-5787-492d-b967-b15fe2acce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_LLM.to_parquet( './data/Silver/data_for_trainning_encoder.parquet' ,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
